# spark-sales-analytics-pipeline

## ğŸš€ Spark Sales ETL Pipeline

[![Python](https://img.shields.io/badge/Python-3.14-blue)](https://www.python.org/)
[![PySpark](https://img.shields.io/badge/PySpark-3.5.0-orange)](https://spark.apache.org/)

---

## ğŸ’¡ Project Overview

This project is a **Batch ETL pipeline** built with **PySpark** to process raw sales data, calculate analytics, and save processed outputs.  

It demonstrates skills in:  
- Data extraction, transformation, and loading (ETL)  
- Analytics using Spark DataFrames and SQL  
- Handling large datasets efficiently with PySpark  
- Generating meaningful business insights from raw sales data  

---

## ğŸ›  Tech Stack

- Python 3.x  
- PySpark 3.5.0  
- Pandas (optional, for validation or additional analytics)  
- CSV files for input and output  

---

## ğŸ“ Project Structure

spark-sales-analytics-pipeline/
â”‚
â”œâ”€ data/
â”‚ â”œâ”€ raw/ # Raw input CSV (sales.csv)
â”‚ â””â”€ processed/ # Processed outputs (ignored in Git)
â”‚
â”œâ”€ spark_etl/
â”‚ â”œâ”€ extract.py # Extracts data from CSV
â”‚ â”œâ”€ transform.py # Aggregates and computes analytics
â”‚ â”œâ”€ load.py # Saves processed data
â”‚ â””â”€ run_pipeline.py # Orchestrates the ETL pipeline
â”‚
â”œâ”€ scripts/
â”‚ â””â”€ create_spark_session.py # Spark session setup
â”‚
â”œâ”€ requirements.txt # Project dependencies
â””â”€ README.md # Project documentation




## âš¡ How to Run the Pipeline

1. Install dependencies:

```bash
pip install -r requirements.txt


2. Run the ETL pipeline:

PYTHONPATH=. python3 spark_etl/run_pipeline.py
Processed output files will be saved in data/processed/.

ğŸ“Š Outputs

| File / Folder        | Description                    |
| -------------------- | ------------------------------ |
| `sales_transformed/` | Full transformed sales dataset |
| `total_revenue/`     | Total revenue by country       |
| `total_quantity/`    | Total quantity sold by country |
| `top_products/`      | Top 5 products by revenue      |
| `daily_revenue/`     | Revenue trends by date         |
